import os
from dotenv import load_dotenv

# --------------------------------------------------------------------------
# [ì„¤ì • ì˜ì—­] ì¹œêµ¬ë“¤ì´ ì—¬ê¸°ì„œ ì›í•˜ëŠ” AIë¥¼ ì„ íƒí•˜ì„¸ìš”!
# --------------------------------------------------------------------------
# ì‚¬ìš©í•˜ê³  ì‹¶ì€ AI ì„œë¹„ìŠ¤ì˜ ì´ë¦„ì„ ì•„ë˜ ë³€ìˆ˜ì— ì ì–´ì£¼ì„¸ìš”.
# ê°€ëŠ¥í•œ ì˜µì…˜: 'gemini', 'groq', 'openai'
CURRENT_AI_PROVIDER = 'gemini' 

# ëª¨ë¸ ì„¤ì •
MODEL_CONFIG = {
    # 2025ë…„ ê¸°ì¤€ ê°€ì¥ ë¹ ë¥´ê³  ë¬´ë£Œ ì¿¼í„°ê°€ ë„‰ë„‰í•œ ëª¨ë¸ (í•„ìˆ˜!)
    'gemini': 'gemini-2.5-flash-lite',     
    'groq': 'llama-3.3-70b-versatile',
    'openai': 'gpt-4o-mini'
}
# --------------------------------------------------------------------------

load_dotenv()

def get_prompt(product_info, user_context):
    """ëª¨ë“  AIì—ê²Œ ê³µí†µìœ¼ë¡œ ë³´ë‚¼ ì§ˆë¬¸(í”„ë¡¬í”„íŠ¸)ì„ ë§Œë“œëŠ” í•¨ìˆ˜"""
    # product_infoê°€ ë¹„ì–´ìˆì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
    if not product_info:
        product_info = {}

    return f"""
    ë‹¹ì‹ ì€ 10ë…„ ì°¨ ë² í…Œë‘ ë·°í‹° ì¹´í”¼ë¼ì´í„°ì…ë‹ˆë‹¤.
    ì•„ë˜ ê³ ê° ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì œí’ˆì„ ì¶”ì²œí•˜ëŠ” ì§§ê³  ë§¤ë ¥ì ì¸ ë©”ì‹œì§€(ì¹´ì¹´ì˜¤í†¡/SMSìš©)ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

    [ê³ ê° ì •ë³´]
    {user_context}

    [ì¶”ì²œ ì œí’ˆ ì •ë³´]
    - ì œí’ˆëª…: {product_info.get('name', 'ì œí’ˆëª… ì—†ìŒ')}
    - ê°€ê²©: {product_info.get('price', 'ê°€ê²© ë¯¸ì •')}ì›
    - íŠ¹ì§•: {product_info.get('skin_type', '')} ì¶”ì²œ
    
    (ì°¸ê³ : ì œí’ˆ ë°ì´í„°ì— ë” ìì„¸í•œ íŠ¹ì§•ì´ë‚˜ ë¦¬ë·°ê°€ ìˆë‹¤ë©´ ë°˜ì˜í•´ì£¼ì„¸ìš”)

    [ìš”ì²­ì‚¬í•­]
    1. ê³ ê°ì˜ ì´ë¦„ê³¼ ê³ ë¯¼ì„ ì–¸ê¸‰í•˜ë©° ê³µê°í•´ì£¼ì„¸ìš”.
    2. ì œí’ˆì˜ íŠ¹ì§•ì´ ì™œ ê³ ê°ì—ê²Œ í•„ìš”í•œì§€ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°í•˜ì„¸ìš”.
    3. ë”°ëœ»í•˜ê³  ì „ë¬¸ì ì¸ í†¤ì•¤ë§¤ë„ˆë¥¼ ìœ ì§€í•˜ì„¸ìš”.
    4. ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•˜ê³ , 300ì ì´ë‚´ë¡œ ì‘ì„±í•˜ì„¸ìš”.
    5. í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”.
    """

def generate_marketing_copy(product_info, user_context):
    """ì„¤ì •ëœ AI ì œê³µìì— ë”°ë¼ ë§ˆì¼€íŒ… ì¹´í”¼ë¥¼ ìƒì„±í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜"""
    # í”„ë¡¬í”„íŠ¸ ìƒì„± (ì—¬ê¸°ì„œ ì—ëŸ¬ê°€ ë‚˜ë©´ product_info ë°ì´í„°ë¥¼ í™•ì¸í•´ì•¼ í•¨)
    prompt = get_prompt(product_info, user_context)
    
    try:
        # ì„¤ì •ëœ AIì— ë”°ë¼ í•¨ìˆ˜ í˜¸ì¶œ
        if CURRENT_AI_PROVIDER == 'gemini':
            return _use_gemini(prompt)
        elif CURRENT_AI_PROVIDER == 'groq':
            return _use_groq(prompt)
        elif CURRENT_AI_PROVIDER == 'openai':
            return _use_openai(prompt)
        else:
            return "ğŸš¨ ì˜¤ë¥˜: CURRENT_AI_PROVIDER ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”!"
            
    except Exception as e:
        # ì—ëŸ¬ ë°œìƒ ì‹œ ìƒì„¸ ë‚´ìš©ì„ ì¶œë ¥í•´ì„œ ì›ì¸ì„ ì°¾ê¸° ì‰½ê²Œ í•¨
        return f"ì£„ì†¡í•©ë‹ˆë‹¤. ë©”ì‹œì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤ ({CURRENT_AI_PROVIDER}): {str(e)}"

# ==========================================================================
# ì•„ë˜ëŠ” ê° AI ì„œë¹„ìŠ¤ë³„ ì—°ê²° í•¨ìˆ˜ë“¤ì…ë‹ˆë‹¤. (ë‚´ë¶€ì ìœ¼ë¡œ ì‚¬ìš©ë¨)
# ==========================================================================

def _use_gemini(prompt):
    """Google Gemini ì‚¬ìš©"""
    import google.generativeai as genai
    
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        return "ğŸš¨ ì—ëŸ¬: .env íŒŒì¼ì— GOOGLE_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤."
        
    genai.configure(api_key=api_key)
    
    # ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
    try:
        model = genai.GenerativeModel(MODEL_CONFIG['gemini'])
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"Gemini í˜¸ì¶œ ì˜¤ë¥˜: {e}"

def _use_groq(prompt):
    """Groq (Llama3) ì‚¬ìš©"""
    try:
        from groq import Groq
    except ImportError:
        return "ğŸš¨ ì—ëŸ¬: groq ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (pip install groq)"
    
    api_key = os.getenv("GROQ_API_KEY")
    if not api_key:
        return "ğŸš¨ ì—ëŸ¬: .env íŒŒì¼ì— GROQ_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤."

    client = Groq(api_key=api_key)
    chat_completion = client.chat.completions.create(
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” ë·°í‹° ë§ˆì¼€í„°ì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ],
        model=MODEL_CONFIG['groq'],
        temperature=0.7,
    )
    return chat_completion.choices[0].message.content

def _use_openai(prompt):
    """OpenAI (GPT) ì‚¬ìš©"""
    try:
        from openai import OpenAI
    except ImportError:
        return "ğŸš¨ ì—ëŸ¬: openai ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (pip install openai)"
    
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        return "ğŸš¨ ì—ëŸ¬: .env íŒŒì¼ì— OPENAI_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤."

    client = OpenAI(api_key=api_key)
    response = client.chat.completions.create(
        model=MODEL_CONFIG['openai'],
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” ë·°í‹° ë§ˆì¼€í„°ì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.7
    )
    return response.choices[0].message.content